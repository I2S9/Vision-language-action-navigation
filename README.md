# Vision-Language-Action Navigation

> This project implements a Vision-Language-Action (VLA) system for robotic navigation in a simulated environment. The system designs an embodied AI agent that can execute natural language navigation instructions using visual perception and learned decision-making policies.
